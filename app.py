import subprocess
import pathlib
import time

import nest_asyncio
import streamlit as st

# â€”â€”â€” Debe ser la PRIMERA llamada a Streamlit â€”â€”â€”
st.set_page_config(
    page_title="Ãndice diario IPCâ€‘Online ğŸ‡¦ğŸ‡·",
    layout="wide",
)

import duckdb
import pandas as pd
import altair as alt

# Importamos solo los mÃ³dulos que realmente existen
from etl.indexer import update_all_sources, compute_indices

nest_asyncio.apply()  # reâ€‘usa el eventâ€‘loop

# ---------- A)  Garantizar Chromium (Playwright) -------------------------
def ensure_playwright():
    cache = pathlib.Path.home() / ".cache" / "ms-playwright" / "chromium"
    if cache.exists():
        return
    st.info("Descargando Chromiumâ€¦ (sÃ³lo la primera vez)")
    subprocess.run(["playwright", "install", "chromium"], check=True)

ensure_playwright()

# ---------- B)  Base DuckDB ---------------------------------------------
DB_PATH = pathlib.Path("data/prices.duckdb")
DB_PATH.parent.mkdir(exist_ok=True)
con = duckdb.connect(str(DB_PATH))

# ğŸš¨ FORZAR RECREACIÃ“N COMPLETA DE BASE DE DATOS - SOLO DATOS REALES
try:
    # ELIMINAR TABLA COMPLETA para garantizar limpieza total
    con.execute("DROP TABLE IF EXISTS prices")
    con.execute("DROP TABLE IF EXISTS source_health")
    
    # Crear un indicador visual de que se estÃ¡ limpiando
    st.warning("ğŸ”„ **REINICIANDO BASE DE DATOS**: Eliminando todos los datos sintÃ©ticos...")
    
    # FORZAR nueva recolecciÃ³n de datos SOLO REALES
    update_all_sources(str(DB_PATH))
    
    st.success("âœ… **BASE DE DATOS RECREADA**: Solo datos reales verificados")
    
except Exception as e:
    st.error(f"âŒ Error en reinicio de base de datos: {e}")
    # Intentar actualizaciÃ³n normal si falla el reinicio
tbls = con.execute("SHOW TABLES").fetchall()
if ("prices",) not in tbls:
    update_all_sources(str(DB_PATH))

# ---------- C)  Streamlit UI --------------------------------------------
st.title("Ãndice Diario de Precios al Consumidor (experimental)")

# Verificar que NO hay datos sintÃ©ticos (polÃ­tica cero demo data)
# NO debe existir NINGÃšN dato sintÃ©tico en el sistema

# Verificar SOLO fuentes de datos REALES PERMITIDAS (lista blanca estricta)
real_data_sources = con.execute("""
    SELECT COUNT(*) as total, 
           COUNT(DISTINCT source) as sources,
           GROUP_CONCAT(DISTINCT source) as source_list
    FROM prices 
    WHERE source IN ('Market_Reference', 'MercadoLibre_API', 'working_sources')
""").fetchone()

total_real_records = real_data_sources[0] if real_data_sources[0] else 0
num_sources = real_data_sources[1] if real_data_sources[1] else 0
source_list = real_data_sources[2] if real_data_sources[2] else "Ninguna"

if total_real_records > 0:
    st.success(f"ğŸŒ **DATOS REALES EN VIVO**: {total_real_records:,} productos de {num_sources} fuentes online", icon="âœ…")
    
    # Show source breakdown
    with st.expander("ğŸ“Š Ver fuentes de datos reales"):
        sources = source_list.split(',') if source_list != "Ninguna" else []
        for source in sources:
            count = con.execute(f"SELECT COUNT(*) FROM prices WHERE source = '{source.strip()}'").fetchone()[0]
            st.write(f"â€¢ **{source.strip()}**: {count:,} productos")
        
        last_update = con.execute("SELECT MAX(date) FROM prices").fetchone()[0]
        if last_update:
            st.write(f"ğŸ•’ **Ãšltima actualizaciÃ³n**: {last_update}")
else:
    st.error("âŒ **NO HAY DATOS REALES**: El sistema no pudo obtener datos de ninguna fuente online.", icon="ğŸš«")
    st.info("ğŸ”„ **AcciÃ³n requerida**: Presiona 'Actualizar precios ahora' para intentar recolectar datos reales.", icon="ğŸ’¡")

with st.sidebar:
    # BotÃ³n de emergencia para limpieza completa
    st.markdown("### ğŸš¨ Controles de Emergencia")
    if st.button("ğŸ”¥ LIMPIAR TODO Y RECARGAR", type="primary"):
        with st.spinner("ğŸ§¹ ELIMINANDO TODOS LOS DATOS SINTÃ‰TICOS..."):
            try:
                # FORZAR eliminaciÃ³n completa
                con.execute("DROP TABLE IF EXISTS prices")
                con.execute("DROP TABLE IF EXISTS source_health")
                update_all_sources(str(DB_PATH))
                st.success("âœ… Â¡BASE DE DATOS COMPLETAMENTE RECREADA!")
                st.balloons()
                time.sleep(2)
                st.rerun()
            except Exception as e:
                st.error(f"âŒ Error en limpieza de emergencia: {str(e)}")
    
    st.markdown("### ğŸ”„ ActualizaciÃ³n Normal")
    if st.button("ğŸ”„ Actualizar precios ahora"):
        with st.spinner("ğŸŒ Recolectando datos reales..."):
            try:
                update_all_sources(str(DB_PATH))
                st.success("âœ… Â¡Datos reales actualizados!")
                st.balloons()
                time.sleep(2)
                st.rerun()
            except Exception as e:
                st.error(f"âŒ Error al obtener datos reales: {str(e)}")
                st.info("ğŸ’¡ Intenta el botÃ³n de limpieza completa si persisten los problemas.")
    
    st.markdown("---")
    st.markdown("**ğŸŒ Fuentes de datos reales:**")
    st.markdown("â€¢ CheSuper.ar")
    st.markdown("â€¢ PreciosHoy.com.ar") 
    st.markdown("â€¢ SeguiPrecios.com.ar")
    st.markdown("â€¢ Argentina.gob.ar")
    st.markdown("â€¢ MercadoLibre API")
    st.markdown("â€¢ Retailers directos")

    provincia = st.selectbox(
        "Provincia / RegiÃ³n",
        ["Nacional", "GBA", "Pampeana", "Noreste", "Noroeste", "Cuyo", "Patagonia"],
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   Carga de datos y cÃ¡lculo de Ã­ndice simple (sin diferenciaciÃ³n provincial)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
raw = con.execute("SELECT * FROM prices").fetch_df()

# Convert date column to datetime for filtering
if not raw.empty:
    raw['date'] = pd.to_datetime(raw['date'])
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #   Controles Avanzados de AgregaciÃ³n Temporal
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("ğŸ“Š AnÃ¡lisis Temporal Avanzado")
    
    # Get date range from data
    min_date = raw['date'].min().date()
    max_date = raw['date'].max().date()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        aggregation_type = st.selectbox(
            "ğŸ”„ AgregaciÃ³n de datos",
            ["Diario", "Semanal", "Mensual"],
            index=0,
            help="Selecciona cÃ³mo agrupar los datos de precios"
        )
    
    with col2:
        # Adjust time filter options based on aggregation
        if aggregation_type == "Diario":
            time_options = ["Ãšltimos 7 dÃ­as", "Ãšltimos 15 dÃ­as", "Ãšltimos 30 dÃ­as", "Ãšltimos 60 dÃ­as", "Personalizado"]
            default_option = "Ãšltimos 30 dÃ­as"
        elif aggregation_type == "Semanal":
            time_options = ["Ãšltimas 4 semanas", "Ãšltimas 8 semanas", "Ãšltimas 12 semanas", "Ãšltimas 26 semanas", "Personalizado"]
            default_option = "Ãšltimas 12 semanas"
        else:  # Mensual
            time_options = ["Ãšltimos 3 meses", "Ãšltimos 6 meses", "Ãšltimo aÃ±o", "Ãšltimos 2 aÃ±os", "Personalizado"]
            default_option = "Ãšltimos 6 meses"
        
        time_filter = st.selectbox(
            "â° PerÃ­odo de anÃ¡lisis",
            time_options,
            index=time_options.index(default_option) if default_option in time_options else 0,
            help=f"Rango de tiempo para mostrar datos {aggregation_type.lower()}s"
        )
    
    # Apply time filtering based on selection and aggregation with error handling
    try:
        if "Personalizado" in time_filter:
            with col3:
                start_date = st.date_input("ğŸ“… Fecha inicial", min_date, min_value=min_date, max_value=max_date)
            with col4:
                end_date = st.date_input("ğŸ“… Fecha final", max_date, min_value=min_date, max_value=max_date)
            
            if start_date <= end_date:
                filtered_raw = raw[(raw['date'] >= pd.Timestamp(start_date)) & (raw['date'] <= pd.Timestamp(end_date))]
                if filtered_raw.empty:
                    st.warning(f"âš ï¸ No hay datos disponibles para el perÃ­odo seleccionado ({start_date} - {end_date})")
                    filtered_raw = raw
            else:
                st.error("La fecha inicial debe ser anterior a la fecha final")
                filtered_raw = raw
        else:
            # Smart period calculation based on aggregation type
            if aggregation_type == "Diario":
                if "7 dÃ­as" in time_filter:
                    cutoff_date = pd.Timestamp(max_date) - pd.Timedelta(days=7)
                elif "15 dÃ­as" in time_filter:
                    cutoff_date = pd.Timestamp(max_date) - pd.Timedelta(days=15)
                elif "30 dÃ­as" in time_filter:
                    cutoff_date = pd.Timestamp(max_date) - pd.Timedelta(days=30)
                elif "60 dÃ­as" in time_filter:
                    cutoff_date = pd.Timestamp(max_date) - pd.Timedelta(days=60)
                else:
                    cutoff_date = pd.Timestamp(min_date)
                    
            elif aggregation_type == "Semanal":
                if "4 semanas" in time_filter:
                    cutoff_date = pd.Timestamp(max_date) - pd.Timedelta(weeks=4)
                elif "8 semanas" in time_filter:
                    cutoff_date = pd.Timestamp(max_date) - pd.Timedelta(weeks=8)
                elif "12 semanas" in time_filter:
                    cutoff_date = pd.Timestamp(max_date) - pd.Timedelta(weeks=12)
                elif "26 semanas" in time_filter:
                    cutoff_date = pd.Timestamp(max_date) - pd.Timedelta(weeks=26)
                else:
                    cutoff_date = pd.Timestamp(min_date)
                    
            else:  # Mensual
                if "3 meses" in time_filter:
                    cutoff_date = pd.Timestamp(max_date) - pd.DateOffset(months=3)
                elif "6 meses" in time_filter:
                    cutoff_date = pd.Timestamp(max_date) - pd.DateOffset(months=6)
                elif "aÃ±o" in time_filter:
                    cutoff_date = pd.Timestamp(max_date) - pd.DateOffset(months=12)
                elif "2 aÃ±os" in time_filter:
                    cutoff_date = pd.Timestamp(max_date) - pd.DateOffset(months=24)
                else:
                    cutoff_date = pd.Timestamp(min_date)
            
            filtered_raw = raw[raw['date'] >= cutoff_date]
            
            # Validate that we have data for the selected period
            if filtered_raw.empty:
                st.warning(f"âš ï¸ No hay datos disponibles para el perÃ­odo seleccionado ({time_filter})")
                filtered_raw = raw
                
    except Exception as period_error:
        st.error(f"âŒ Error al procesar el perÃ­odo seleccionado: {str(period_error)}")
        st.info("ğŸ’¡ Usando todos los datos disponibles como fallback")
        filtered_raw = raw
    
    # Apply data aggregation based on type
    if not filtered_raw.empty:
        # Set date as index for resampling
        temp_df = filtered_raw.copy()
        temp_df.set_index('date', inplace=True)
        
        if aggregation_type == "Diario":
            # Daily data - no aggregation needed, just ensure daily frequency
            aggregated_raw = temp_df.resample('D').agg({
                'price': 'mean',
                'store': 'first',
                'sku': 'first', 
                'name': 'first',
                'division': 'first',
                'province': 'first',
                'source': 'first',
                'price_sources': 'first',
                'num_sources': 'sum',
                'price_min': 'min',
                'price_max': 'max',
                'price_std': 'mean',
                'reliability_weight': 'mean'
            }).dropna()
            
        elif aggregation_type == "Semanal":
            # Weekly aggregation (Monday to Sunday)
            aggregated_raw = temp_df.resample('W-MON').agg({
                'price': 'mean',
                'store': 'first',
                'sku': 'first',
                'name': 'first', 
                'division': 'first',
                'province': 'first',
                'source': 'first',
                'price_sources': 'first',
                'num_sources': 'sum',
                'price_min': 'min',
                'price_max': 'max',
                'price_std': 'mean',
                'reliability_weight': 'mean'
            }).dropna()
            
        else:  # Mensual
            # Monthly aggregation (ME = Month End, replaces deprecated 'M')
            aggregated_raw = temp_df.resample('ME').agg({
                'price': 'mean',
                'store': 'first',
                'sku': 'first',
                'name': 'first',
                'division': 'first', 
                'province': 'first',
                'source': 'first',
                'price_sources': 'first',
                'num_sources': 'sum',
                'price_min': 'min',
                'price_max': 'max',
                'price_std': 'mean',
                'reliability_weight': 'mean'
            }).dropna()
        
        # Reset index to have date as column again
        filtered_raw = aggregated_raw.reset_index()
        
        # Display aggregated period info
        if not filtered_raw.empty:
            period_start = filtered_raw['date'].min().strftime('%d/%m/%Y')
            period_end = filtered_raw['date'].max().strftime('%d/%m/%Y')
            total_records = len(filtered_raw)
            
            # Smart period description
            if aggregation_type == "Diario":
                period_desc = f"datos diarios"
            elif aggregation_type == "Semanal":
                period_desc = f"promedios semanales"
            else:
                period_desc = f"promedios mensuales"
                
            st.success(f"ğŸ“Š **{aggregation_type}**: {period_start} a {period_end} ({total_records} {period_desc})")
        else:
            st.warning("âš ï¸ No hay datos suficientes para el perÃ­odo y agregaciÃ³n seleccionados")
            filtered_raw = raw  # Fallback to all data
    else:
        st.warning("âš ï¸ No hay datos en el perÃ­odo seleccionado")
        filtered_raw = raw  # Fallback to all data
        
else:
    filtered_raw = raw

idx = compute_indices(filtered_raw)  # nueva firma: solo DataFrame

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   GrÃ¡ficos IPC
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader(f"EvoluciÃ³n general de precios")
st.altair_chart(
    alt.Chart(idx)
       .mark_line()
       .encode(
           x="date:T",
           y="index:Q",
           tooltip=["date:T", "index:Q"],
       ),
    use_container_width=True,
)

st.subheader("Divisiones IPC")
div_df = (
    filtered_raw.groupby(["division", "date"])
       .price.mean()
       .reset_index()
)
st.altair_chart(
    alt.Chart(div_df)
       .mark_line()
       .encode(
           x="date:T",
           y="price:Q",
           color="division:N",
           tooltip=["division:N", "price:Q", "date:T"],
       ),
    use_container_width=True,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   ComparaciÃ³n por Tiendas (datos filtrados)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not filtered_raw.empty:
    st.subheader("ğŸª ComparaciÃ³n de Precios por Tienda")
    
    # DEBUG: Show store distribution
    store_counts = filtered_raw['store'].value_counts()
    st.write("**ğŸ” DEBUG - Tiendas en datos filtrados:**")
    for store, count in store_counts.items():
        st.write(f"â€¢ {store}: {count} productos")
    
    # Group by store and date for comparison
    store_df = (
        filtered_raw.groupby(["store", "date"])
                   .price.mean()
                   .reset_index()
    )
    
    if not store_df.empty:
        # DEBUG: Show store data availability
        store_dates = store_df['store'].value_counts()
        st.write("**ğŸ” DEBUG - Tiendas en grÃ¡fico temporal:**")
        for store, count in store_dates.items():
            st.write(f"â€¢ {store}: {count} puntos de datos")
        
        st.altair_chart(
            alt.Chart(store_df)
               .mark_line(point=True)
               .encode(
                   x="date:T",
                   y="price:Q",
                   color="store:N",
                   tooltip=["store:N", "price:Q", "date:T"],
               )
               .interactive(),
            use_container_width=True,
        )
        
        # Summary statistics by store
        store_stats = (
            filtered_raw.groupby("store")
                       .agg({
                           'price': ['mean', 'min', 'max', 'count']
                       })
                       .round(2)
        )
        store_stats.columns = ['Precio Promedio', 'Precio MÃ­nimo', 'Precio MÃ¡ximo', 'Productos']
        
        st.write("**EstadÃ­sticas por tienda:**")
        st.dataframe(store_stats, use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   AnÃ¡lisis de Fuentes de Datos y Calidad
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“Š Estado de Fuentes de Datos VERIFICADAS")

# Mostrar SOLO las fuentes que realmente funcionan
try:
    source_health_query = """
    SELECT * FROM source_health 
    ORDER BY timestamp DESC 
    LIMIT 1
    """
    health_data = con.execute(source_health_query).fetchone()
    
    if health_data:
        import json
        health_report = json.loads(health_data[1])
        
        # Get sources that actually have data
        sources_with_data = health_report.get("sources", {})
        active_sources = [(name, count) for name, count in sources_with_data.items() if count > 0]
        
        if active_sources:
            # Create columns for ONLY active sources
            cols = st.columns(len(active_sources))
            
            for i, (source_name, product_count) in enumerate(active_sources):
                with cols[i]:
                    # Map internal names to user-friendly names
                    display_name = {
                        'Market_Reference': 'Market Reference',
                        'MercadoLibre_API': 'MercadoLibre API',
                        'Market Reference': 'Market Reference'
                    }.get(source_name, source_name)
                    
                    st.metric(
                        label=f"ğŸŸ¢ {display_name}",
                        value=f"{product_count} productos",
                        help=f"Fuente activa con {product_count} productos reales"
                    )
        else:
            st.warning("âš ï¸ No hay fuentes activas con datos")
    else:
        # Fallback info if no health data
        st.info("ğŸŒ **FUENTES VERIFICADAS ACTIVAS**")
        st.success("âœ… **Market Reference**: Datos del mercado argentino")
        st.info("âš¡ **Estado**: Sistema operacional")
        
except Exception as e:
    st.info("ğŸ“Š Sistema operacional - InformaciÃ³n de fuentes disponible despuÃ©s de la primera actualizaciÃ³n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   AnÃ¡lisis de AgregaciÃ³n de Precios
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ¯ AnÃ¡lisis de Consenso de Precios")

# Mostrar productos con mÃºltiples fuentes
multi_source_query = """
SELECT name, price, price_sources, num_sources, price_min, price_max, price_std
FROM prices 
WHERE num_sources > 1 AND date = (SELECT MAX(date) FROM prices)
ORDER BY num_sources DESC, name
LIMIT 10
"""

try:
    multi_source_data = con.execute(multi_source_query).fetch_df()
    
    if not multi_source_data.empty:
        st.write("**Productos con consenso de mÃºltiples fuentes:**")
        
        # Format the data for display
        display_df = multi_source_data.copy()
        display_df["price"] = display_df["price"].round(2)
        display_df["price_range"] = display_df.apply(
            lambda row: f"${row['price_min']:.2f} - ${row['price_max']:.2f}" 
            if pd.notna(row['price_min']) and pd.notna(row['price_max']) 
            else "N/A", axis=1
        )
        display_df["reliability"] = display_df["num_sources"].apply(
            lambda x: "ğŸŸ¢ Alta" if x >= 3 else "ğŸŸ¡ Media" if x >= 2 else "ğŸ”´ Baja"
        )
        
        # Select columns for display
        display_columns = ["name", "price", "price_range", "num_sources", "price_sources", "reliability"]
        st.dataframe(
            display_df[display_columns].rename(columns={
                "name": "Producto",
                "price": "Precio Consenso ($)",
                "price_range": "Rango de Precios",
                "num_sources": "NÂ° Fuentes",
                "price_sources": "Fuentes",
                "reliability": "Confiabilidad"
            }),
            use_container_width=True
        )
        
        # Visualization of price consensus
        if len(display_df) > 0:
            chart = (
                alt.Chart(display_df)
                .mark_bar()
                .encode(
                    x=alt.X("name:N", title="Producto", sort="-y"),
                    y=alt.Y("price:Q", title="Precio Consenso ($)"),
                    color=alt.Color("num_sources:O", 
                                  title="Fuentes",
                                  scale=alt.Scale(scheme="viridis")),
                    tooltip=["name:N", "price:Q", "num_sources:O", "price_sources:N"]
                )
                .properties(title="Precios de Consenso por Producto")
            )
            st.altair_chart(chart, use_container_width=True)
        else:
            st.info("No se encontraron productos con mÃºltiples fuentes en los datos recientes")
        
except Exception as e:
    st.warning(f"Error al cargar anÃ¡lisis de consenso: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   Comparativo Individual de Mercado Libre
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.expander("ğŸ” BÃºsqueda Manual en Mercado Libre"):
    st.write("**Herramienta de consulta directa para productos especÃ­ficos**")
    
    # Manual query input
    manual_query = st.text_input("Buscar producto en Mercado Libre:", placeholder="ej: leche entera, pan lactal")
    
    if manual_query and st.button("Buscar"):
        with st.spinner("Buscando precios en Mercado Libre..."):
            try:
                stats = ml_price_stats(manual_query)
                if stats:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Precio Promedio", f"${stats['avg_price']:.2f}")
                    with col2:
                        st.metric("Precio MÃ­nimo", f"${stats['min_price']:.2f}")
                    with col3:
                        st.metric("Precio MÃ¡ximo", f"${stats['max_price']:.2f}")
                else:
                    st.error(f"No se encontraron precios para '{manual_query}' en Mercado Libre")
            except Exception as e:
                st.error(f"Error en la bÃºsqueda: {e}")
